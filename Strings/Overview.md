# Reconstructing Strings From Random Traces
\cite{batu2004reconstructing} by Tugkan Batu, Sampath Kannan, Sanjeev Khanna, and Andrew McGregor. This paper introduces the problem of string trace reconstruction. 
    
The motivation is the ``sequence-alignment problem'' from biology, which is the problem of aligning a sequence (or string) of DNA characters, given that the sequences underwent mutations which can add, delete or replace elements of the sequence. They assume a simplified version of the problem, where only deletions are allowed as sequence mutations. 

Formally, their problem statement is: given a string $t$ of length $n$, each trace $\tilde{t}$ (using my own notation for this) is a generated by taking each element of the string and deleting it with probability $p$. They ask, how many traces, $m$, are required to fully reconstruct the string $t$ with high probability?

To solve this problem they use an algorithm they call ``Bitwise Majority Alignment'', which attempts to find an index-based alignment, so that the majority of the traces will be in agreement on what the next element of the string is. More clearly, for each trace $\tilde{t}_1$, $\dots$, $\tilde{t}_m$, they look at an index variable that will point to what the trace thinks should be the next element of the string. Then, by using a majority voting scheme, the algorithm decides what the next value of the string should be, and those traces that agreed with the vote get moved up an index, and those that did not agree with the vote will not have their index incremented. The idea is that if an element was deleted from a trace then when the algorithm gets to the string index that was deleted from the trace, it will hold the trace back one step when it disagrees with the majority (and the majority will not have that element deleted by averaging), it will be held back one step because of its disagreement, which will bring it in alignment with the actual values of the original string $t$. 

The paper provides these guarantees: For the vast majority of strings, and $p = O(\frac{1}{\log(n)})$, they can reconstruct the string with only $m = O(
\log(n))$ traces. They also show that $m=\Omega(\frac{\log(n)}{\log(\log(n))})$ strings are necessary to recover the original string. As another result, they show that if $p = \Omega(1 / n^{1/2 + \varepsilon})$ they can recover a string very close to the original string with only $m = O(\frac{1}{\varepsilon})$ traces. 


# Trace Reconstruction: Generalized and Parameterized
\cite{krishnamurthy2021trace} by Akshay Krishnamurthy, Arya Mazumdar, Andrew McGregor, and Soumyabrata Pal. This paper covers several versions of the string trace reconstruction problem. In particular they deal with string trace reconstruction for $k$-sparse strings, and a matrix trace reconstruction problem for worst case and randomly generated matrices. In this paper, they have $p$ being the deletion probability (though they also deal with specific variants involving different deletion probabilities for $1$'s and $0$'s), $n$ the length of the string or total number of elements in the matrix, and $m$ being the number of traces required. 

They employ four different techniques for proving all of these results: learning the parameters of a binomial mixture distribution, hierarchical clustering, a k-deck combinatorial argument, and a multivariate polynomial complex analysis technique (similar to previous works with evaluating Littlewood polynomials). 

Their results are as follows: 
- *Theorem 1*: For a string $x \in \{0,1 \}^n$, with at most $k$ non-zero elements, then assuming $1 - p = \Omega( k^{-1/2} \log(n) )$, $m = \exp\{ O( (k/(1-p))^{1/3} \log^{2/3}(n) ) \}$ traces will allow recovery with high probability.
- *Theorem 2*: Again, $k$ being the sparsity of the string. If each $1$ is separated by at least $\Omega(k \log(n) )$ 0's, then for any $p$ poly$(n)$ traces suffice.
- *Theorem 3*: For any $x,y \in \{0,1\}$ with Hamming distance $d_H(x,y) \leq 2k$, and if $p \leq 1 - k/n$, then $\exp\{O(k \log(n))\}$ traces are enough to distinguish between $x$ and $y$.
- *Theorem 4*: They define a matrix deletion for a $\sqrt{n} \times \sqrt{n}$-dimensional matrix to be where you delete row and column $i$ with probability $p$ (both row and column are deleted at the same time). Then $\exp\{O(n^{1/4}/(1-p) \sqrt{p \log(n)})\}$ traces are sufficient to recover the matrix with high probability.
- *Theorem 5*: Let $X \in \{ 0,1 \}^{\sqrt{n} \times \sqrt{n}}$ be such that each element has distribution Bern(1/2). Then $O(\log(n))$ traces suffice to recover $X$ with high probability.

${\textsf{\color{red}TODO: }}$ **Go over the algorithms and the techniques used in this paper.**


# Optimal Mean-Based Algorithms for Trace Reconstruction 
\cite{de2017optimal} by Anindya De, Ryan Oâ€™Donnell, Rocco A. Servedio. This paper provides a very clean solution that gave the state of the art for worst case string trace reconstruction, where they required $m = \exp(O(n)^{1/3})$ traces. This was eventually improved in \cite{chase2020new}, where they improved the result to $m = \exp(O(n)^{1/5})$ using different polynomials and other techniques. 

Ryan O'Donnell explains the paper far better than I could in [this YouTube video](https://www.youtube.com/watch?v=Ys11H5smSIM). 

This paper was a serious step forward in string trace reconstruction, specifically because it showed an equivalence between the string trace reconstruction problem, and finding Littlewood polynomials on an disk in the complex plane with the smallest modulus. They first showed that the worst case string trace reconstruction problem can be made equivlanent to finding a polynomial with small modulus on the unit disk in the complex plane, and then reduced that problem through probabilistic analysis to the eventual problem. 

The paper also showed results for a general deletion, insertion, bit flip channel, though the analysis process was largely the same as the deletion channel. The sample complexity stayed relatively similar to the sample complexity of recovering from the deletion channel. They also found an interesting result, that sometimes more insertions can help with string trace recovery in very specific settings. 






